{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08666ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Hidden Size=32, Layers=3, Activation=ReLU - Loss: 0.0502607524394989\n",
      "Config: Hidden Size=32, Layers=3, Activation=GELU - Loss: 0.018592871725559235\n",
      "Config: Hidden Size=32, Layers=3, Activation=Tanh - Loss: 0.26835495233535767\n",
      "Config: Hidden Size=32, Layers=4, Activation=ReLU - Loss: 0.04083538427948952\n",
      "Config: Hidden Size=32, Layers=4, Activation=GELU - Loss: 0.00011622115562204272\n",
      "Config: Hidden Size=32, Layers=4, Activation=Tanh - Loss: 0.009346365928649902\n",
      "Config: Hidden Size=32, Layers=5, Activation=ReLU - Loss: 0.016851380467414856\n",
      "Config: Hidden Size=32, Layers=5, Activation=GELU - Loss: 8.861877722665668e-05\n",
      "Config: Hidden Size=32, Layers=5, Activation=Tanh - Loss: 0.007047646678984165\n",
      "Config: Hidden Size=32, Layers=6, Activation=ReLU - Loss: 0.02289504185318947\n",
      "Config: Hidden Size=32, Layers=6, Activation=GELU - Loss: 0.0002243544877273962\n",
      "Config: Hidden Size=32, Layers=6, Activation=Tanh - Loss: 0.01073321420699358\n",
      "Config: Hidden Size=50, Layers=3, Activation=ReLU - Loss: 0.0435788594186306\n",
      "Config: Hidden Size=50, Layers=3, Activation=GELU - Loss: 0.00014749611727893353\n",
      "Config: Hidden Size=50, Layers=3, Activation=Tanh - Loss: 0.002580875065177679\n",
      "Config: Hidden Size=50, Layers=4, Activation=ReLU - Loss: 0.022750334814190865\n",
      "Config: Hidden Size=50, Layers=4, Activation=GELU - Loss: 0.00013740552822127938\n",
      "Config: Hidden Size=50, Layers=4, Activation=Tanh - Loss: 0.002593684708699584\n",
      "Config: Hidden Size=50, Layers=5, Activation=ReLU - Loss: 0.022501878440380096\n",
      "Config: Hidden Size=50, Layers=5, Activation=GELU - Loss: 4.5351654989644885e-05\n",
      "Config: Hidden Size=50, Layers=5, Activation=Tanh - Loss: 0.005779710132628679\n",
      "Config: Hidden Size=50, Layers=6, Activation=ReLU - Loss: 0.017085572704672813\n",
      "Config: Hidden Size=50, Layers=6, Activation=GELU - Loss: 0.009517000988125801\n",
      "Config: Hidden Size=50, Layers=6, Activation=Tanh - Loss: 0.005224992521107197\n",
      "Config: Hidden Size=64, Layers=3, Activation=ReLU - Loss: 0.041029661893844604\n",
      "Config: Hidden Size=64, Layers=3, Activation=GELU - Loss: 0.0002323533408343792\n",
      "Config: Hidden Size=64, Layers=3, Activation=Tanh - Loss: 0.0007875633891671896\n",
      "Config: Hidden Size=64, Layers=4, Activation=ReLU - Loss: 0.017344605177640915\n",
      "Config: Hidden Size=64, Layers=4, Activation=GELU - Loss: 0.00011141851427964866\n",
      "Config: Hidden Size=64, Layers=4, Activation=Tanh - Loss: 0.0030373765621334314\n",
      "Config: Hidden Size=64, Layers=5, Activation=ReLU - Loss: 0.014495523646473885\n",
      "Config: Hidden Size=64, Layers=5, Activation=GELU - Loss: 5.431307727121748e-05\n",
      "Config: Hidden Size=64, Layers=5, Activation=Tanh - Loss: 0.003946319688111544\n",
      "Config: Hidden Size=64, Layers=6, Activation=ReLU - Loss: 0.011808940209448338\n",
      "Config: Hidden Size=64, Layers=6, Activation=GELU - Loss: 0.00014098679821472615\n",
      "Config: Hidden Size=64, Layers=6, Activation=Tanh - Loss: 0.00546044297516346\n",
      "Config: Hidden Size=128, Layers=3, Activation=ReLU - Loss: 0.03789981082081795\n",
      "Config: Hidden Size=128, Layers=3, Activation=GELU - Loss: 0.00010020029003499076\n",
      "Config: Hidden Size=128, Layers=3, Activation=Tanh - Loss: 0.0003647435805760324\n",
      "Config: Hidden Size=128, Layers=4, Activation=ReLU - Loss: 0.019893504679203033\n",
      "Config: Hidden Size=128, Layers=4, Activation=GELU - Loss: 0.0003610909916460514\n",
      "Config: Hidden Size=128, Layers=4, Activation=Tanh - Loss: 0.000345035019563511\n",
      "Config: Hidden Size=128, Layers=5, Activation=ReLU - Loss: 0.02624659612774849\n",
      "Config: Hidden Size=128, Layers=5, Activation=GELU - Loss: 0.0001760293380357325\n",
      "Config: Hidden Size=128, Layers=5, Activation=Tanh - Loss: 0.00036800833186134696\n",
      "Config: Hidden Size=128, Layers=6, Activation=ReLU - Loss: 0.013700462877750397\n",
      "Config: Hidden Size=128, Layers=6, Activation=GELU - Loss: 0.0002830289304256439\n",
      "Config: Hidden Size=128, Layers=6, Activation=Tanh - Loss: 0.002608361653983593\n",
      "\n",
      "Mejor configuración: Hidden Size=50, Layers=5, Activation=GELU - Loss: 4.5351654989644885e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# Definimos posibles valores para el grid search\n",
    "hidden_sizes = [32, 50, 64, 128]        # Tamaños de capas ocultas\n",
    "num_layers_list = [3, 4, 5, 6]          # Número de capas ocultas\n",
    "activation_functions = [nn.ReLU, nn.GELU, nn.Tanh]  # Funciones de activación\n",
    "\n",
    "# Creamos una clase flexible de PINN con configuraciones variables\n",
    "class FlexibleNeuralNet(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, activation_fn, output_size=1, input_size=1):\n",
    "        super(FlexibleNeuralNet, self).__init__()\n",
    "        layers = []\n",
    "        \n",
    "        # Capa de entrada\n",
    "        layers.append(nn.Linear(input_size, hidden_size))\n",
    "        layers.append(activation_fn())\n",
    "        \n",
    "        # Capas ocultas\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            layers.append(activation_fn())\n",
    "        \n",
    "        # Capa de salida\n",
    "        layers.append(nn.Linear(hidden_size, output_size))\n",
    "        \n",
    "        # Conectar las capas\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Definimos la función de costo (MSE)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Vector de tiempo como entrada de la NN\n",
    "t_numpy = np.arange(-5, 5 + 0.01, 0.001, dtype=np.float32)\n",
    "t = torch.from_numpy(t_numpy).reshape(len(t_numpy), 1)\n",
    "t.requires_grad_(True)\n",
    "\n",
    "# Parámetros físicos\n",
    "g = 9.8\n",
    "L = 10\n",
    "\n",
    "# Inicializar los resultados del grid search\n",
    "results = []\n",
    "\n",
    "# Grid search\n",
    "for hidden_size, num_layers, activation_fn in itertools.product(hidden_sizes, num_layers_list, activation_functions):\n",
    "    # Inicializar modelo y optimizador\n",
    "    model = FlexibleNeuralNet(hidden_size=hidden_size, num_layers=num_layers, activation_fn=activation_fn)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # Entrenar por unas pocas épocas para evaluación rápida\n",
    "    num_epochs = 500\n",
    "    for epoch in range(num_epochs):\n",
    "        epsilon = torch.normal(0, 0.1, size=(len(t), 1)).float()\n",
    "        t_train = t + epsilon\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(t_train)\n",
    "        \n",
    "        # Calcular derivadas\n",
    "        dy_dt = torch.autograd.grad(y_pred, t_train, grad_outputs=torch.ones_like(y_pred), create_graph=True)[0]\n",
    "        d2y_dt2 = torch.autograd.grad(dy_dt, t_train, grad_outputs=torch.ones_like(dy_dt), create_graph=True)[0]\n",
    "\n",
    "        # Pérdida de la ecuación diferencial\n",
    "        loss_DE = criterion(d2y_dt2 + (g/L)*y_pred, torch.zeros_like(d2y_dt2))\n",
    "        \n",
    "        # Pérdida de la condición inicial\n",
    "        loss_IC = criterion(model(torch.tensor([[0.0]])), torch.tensor([[2.0]]))\n",
    "        \n",
    "        # Pérdida total\n",
    "        loss = loss_DE + loss_IC\n",
    "\n",
    "        # Optimización\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Guardamos los resultados del grid search\n",
    "    results.append({\n",
    "        'hidden_size': hidden_size,\n",
    "        'num_layers': num_layers,\n",
    "        'activation_fn': activation_fn.__name__,\n",
    "        'final_loss': loss.item()\n",
    "    })\n",
    "    print(f'Config: Hidden Size={hidden_size}, Layers={num_layers}, Activation={activation_fn.__name__} - Loss: {loss.item()}')\n",
    "\n",
    "# Mostramos la mejor configuración\n",
    "best_config = min(results, key=lambda x: x['final_loss'])\n",
    "print(f\"\\nMejor configuración: Hidden Size={best_config['hidden_size']}, Layers={best_config['num_layers']}, \"\n",
    "      f\"Activation={best_config['activation_fn']} - Loss: {best_config['final_loss']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "212398a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 1. Crear un heatmap de las pérdidas promedio en escala logarítmica y guardarlo\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m activation_fn \u001b[38;5;129;01min\u001b[39;00m df_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation_fn\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[1;32m      9\u001b[0m     subset \u001b[38;5;241m=\u001b[39m df_results[df_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation_fn\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m activation_fn]\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Convertimos la pérdida a logaritmo para mejorar la visualización\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_results' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Creamos una carpeta para guardar las gráficas, si no existe\n",
    "output_folder = \"heatmaps\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#Creamos un heatmap de las pérdidas promedio en escala logarítmica y guardarlo\n",
    "for activation_fn in df_results['activation_fn'].unique():\n",
    "    subset = df_results[df_results['activation_fn'] == activation_fn]\n",
    "    \n",
    "    # Convertimos la pérdida a logaritmo para mejorar la visualización\n",
    "    subset['log_final_loss'] = np.log10(subset['final_loss'] + 1e-10)  # Evitar log(0) sumando un pequeño valor\n",
    "\n",
    "    heatmap_data = subset.pivot(index=\"hidden_size\", columns=\"num_layers\", values=\"log_final_loss\")\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(heatmap_data, annot=True, fmt=\".3f\", cmap=\"BuGn_r\")\n",
    "    plt.title(f'Heatmap de pérdida final en escala logarítmica - Activación: {activation_fn}')\n",
    "    plt.xlabel('Número de capas ocultas')\n",
    "    plt.ylabel('Tamaño de capa oculta')\n",
    "\n",
    "    # Guardar cada gráfico con el nombre de la función de activación\n",
    "    filename = f\"{output_folder}/heatmap_loss_log_{activation_fn}.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.close()  # Cerrar la figura para liberar memoria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0885f788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
